{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290c89df-b833-4553-8e3e-0bb3ec9d318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import utils\n",
    "import preprocess\n",
    "import data\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c905dc2-1f1d-47be-87b6-3e5570350b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_pattern = 'sei_seq{}_nip_feature{}'.format(1024, 467)\n",
    "\n",
    "# prediction\n",
    "import sei_model as sei\n",
    "\n",
    "prediction_dir = '../cross/taes'\n",
    "prediction_list = [ i for i in os.listdir(prediction_dir) if i[-3:] == '.fa' ]\n",
    "prediction_list = [ i for i in prediction_list if i+'_pm_sei_seq1024_nip_feature467.npy' not in os.listdir(prediction_dir) ]\n",
    "\n",
    "## Note: This is indepent param\n",
    "model_dir = '../model/{}.model'.format(record_pattern)\n",
    "\n",
    "## Restart varibles which will be cleared\n",
    "batch_size=512\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "nfeature = 467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8950808c-725c-4d17-b5e7-798a54cd4ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taes_1k_128s_filtered_chr4D2.fa',\n",
       " 'taes_1k_128s_filtered_chr4D3.fa',\n",
       " 'taes_1k_128s_filtered_chr5A0.fa',\n",
       " 'taes_1k_128s_filtered_chr5A1.fa',\n",
       " 'taes_1k_128s_filtered_chr5A2.fa',\n",
       " 'taes_1k_128s_filtered_chr5A3.fa',\n",
       " 'taes_1k_128s_filtered_chr5B0.fa',\n",
       " 'taes_1k_128s_filtered_chr5B1.fa',\n",
       " 'taes_1k_128s_filtered_chr5B2.fa',\n",
       " 'taes_1k_128s_filtered_chr2A1.fa',\n",
       " 'taes_1k_128s_filtered_chr3A3.fa',\n",
       " 'taes_1k_128s_filtered_chr4B1.fa',\n",
       " 'taes_1k_128s_filtered_chr5B3.fa',\n",
       " 'taes_1k_128s_filtered_chr6D1.fa',\n",
       " 'taes_1k_128s_filtered_chr5D0.fa',\n",
       " 'taes_1k_128s_filtered_chr5D1.fa',\n",
       " 'taes_1k_128s_filtered_chr5D2.fa',\n",
       " 'taes_1k_128s_filtered_chr5D3.fa',\n",
       " 'taes_1k_128s_filtered_chr6A0.fa',\n",
       " 'taes_1k_128s_filtered_chr6A1.fa',\n",
       " 'taes_1k_128s_filtered_chr6A2.fa',\n",
       " 'taes_1k_128s_filtered_chr6A3.fa',\n",
       " 'taes_1k_128s_filtered_chr6B0.fa',\n",
       " 'taes_1k_128s_filtered_chr6B1.fa',\n",
       " 'taes_1k_128s_filtered_chr6B2.fa',\n",
       " 'taes_1k_128s_filtered_chr6B3.fa',\n",
       " 'taes_1k_128s_filtered_chr6D0.fa',\n",
       " 'taes_1k_128s_filtered_chr6D2.fa',\n",
       " 'taes_1k_128s_filtered_chr6D3.fa',\n",
       " 'taes_1k_128s_filtered_chr7A0.fa',\n",
       " 'taes_1k_128s_filtered_chr7A1.fa',\n",
       " 'taes_1k_128s_filtered_chr7A2.fa',\n",
       " 'taes_1k_128s_filtered_chr7A3.fa',\n",
       " 'taes_1k_128s_filtered_chr7B0.fa',\n",
       " 'taes_1k_128s_filtered_chr7B1.fa',\n",
       " 'taes_1k_128s_filtered_chr7B2.fa',\n",
       " 'taes_1k_128s_filtered_chr7B3.fa',\n",
       " 'taes_1k_128s_filtered_chr7D0.fa',\n",
       " 'taes_1k_128s_filtered_chr7D1.fa',\n",
       " 'taes_1k_128s_filtered_chr7D2.fa',\n",
       " 'taes_1k_128s_filtered_chr7D3.fa',\n",
       " 'taes_1k_128s_filtered_chrUn0.fa',\n",
       " 'taes_1k_128s_filtered_chrUn1.fa',\n",
       " 'taes_1k_128s_filtered_chrUn2.fa',\n",
       " 'taes_1k_128s_filtered_chrUn3.fa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa26ae52-42fa-4b4e-9785-4eff5f4aeb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def sc_projection(chromatin_profile_preds, clustervfeat):\n",
    "    return np.dot(chromatin_profile_preds, clustervfeat.T)\n",
    "\n",
    "ordered_profiles = np.load('../prediction/{}.cluster_ordered_profiles.npy'.format(record_pattern))\n",
    "\n",
    "\n",
    "leiden_wgt = np.load('../visualization/{}.leiden.npy'.format(record_pattern))\n",
    "cluster_def = np.load('../visualization/{}.cluster_def.npy'.format(record_pattern), allow_pickle=True).item()\n",
    "ordered_category = np.array([ cluster_def['category']['cluster'+str(cluster)] for cluster in sorted(np.unique(leiden_wgt)) if 'cluster'+str(cluster) in cluster_def['category'] ])\n",
    "\n",
    "\n",
    "def statis_scores(ordered_category, total_pre_scores):\n",
    "    asc_ind = {}\n",
    "    for i, rec in enumerate(ordered_category):\n",
    "        if rec in asc_ind:\n",
    "            asc_ind[rec].append(i)\n",
    "        else:\n",
    "            asc_ind[rec] = [i]\n",
    "    \n",
    "    result = []\n",
    "    max_result = []\n",
    "    for rec in total_pre_scores:\n",
    "        tmp = {}\n",
    "        max_key = ''\n",
    "        max_value = 0\n",
    "        for key in asc_ind:\n",
    "            tmp[key] = np.sum(rec[asc_ind[key]])\n",
    "            if tmp[key] > max_value:\n",
    "                max_key = key\n",
    "                max_value = tmp[key]\n",
    "        result.append(tmp)\n",
    "        max_result.append(max_key)\n",
    "    \n",
    "    return result, collections.Counter(max_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3a195-0bac-4eac-a4d3-d9218b52d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_dir)\n",
    "model.eval()\n",
    "\n",
    "predict_dict = {}\n",
    "for prediction_fa in prediction_list:\n",
    "    total_pre = torch.tensor([[0]*nfeature],dtype=torch.float)\n",
    "    \n",
    "    pre_seqs = utils.load_data('/'.join([prediction_dir,prediction_fa]))\n",
    "    print('Total {} seqs from {}'.format(len(pre_seqs), prediction_fa))\n",
    "    \n",
    "    pre_nuc_pre = preprocess.NucPreprocess(pre_seqs)\n",
    "    pre_X_all = pre_nuc_pre.onehot_for_nuc()\n",
    "    print('Encoding done for {}'.format(prediction_fa))\n",
    "    \n",
    "    pre_dataset = data.NucDataset(x=pre_X_all, y=[0]*len(pre_X_all))\n",
    "    pre_loader = torch.utils.data.DataLoader(dataset=pre_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        print('Start prediction, total: ', len(pre_X_all))\n",
    "        for i, (inputs, _) in tqdm(enumerate(pre_loader)):\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            inputs = inputs.permute(0,2,1)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "            total_pre = torch.concat((total_pre, outputs.to(cpu, dtype=torch.float)))\n",
    "    \n",
    "    total_pre = total_pre[1:].numpy()\n",
    "    np.save('{}/{}_pm_{}.npy'.format(prediction_dir, prediction_fa, record_pattern),total_pre)\n",
    "    \n",
    "\n",
    "    # statis\n",
    "    total_pre_scores = sc_projection(total_pre, ordered_profiles)\n",
    "    np.save('{}/{}_cluster_{}.npy'.format(prediction_dir, prediction_fa, record_pattern), total_pre_scores)\n",
    "    \n",
    "    result, max_result = statis_scores(ordered_category, total_pre_scores)\n",
    "    \n",
    "    predict_dict[prediction_fa] = {'total_pre': total_pre, 'sta_res': result, 'sta_max': max_result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "64746219-6ece-498d-b49f-a8f81a28bcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_n100k_w1k_noN.fa Counter({'Heterochromatin': 67451, 'Enhancer': 15361, 'Repressed Polycomb': 7034, 'Transcription': 3409, 'Bivalent TSS': 164})\n",
      "repeat_n100k_w1k_noN.fa Counter({'Heterochromatin': 73280, 'Enhancer': 15572, 'Repressed Polycomb': 5087, 'Transcription': 1974, 'Bivalent TSS': 90})\n",
      "seedlings_H3K27me3.fa Counter({'Heterochromatin': 49088, 'Repressed Polycomb': 35523, 'Transcription': 19679, 'Enhancer': 15668, 'Bivalent TSS': 473})\n",
      "seedlings_H3K36me3.fa Counter({'Enhancer': 29866, 'Transcription': 28678, 'Heterochromatin': 10230, 'Repressed Polycomb': 2221, 'Bivalent TSS': 26})\n",
      "seedlings_H3K4me3.fa Counter({'Transcription': 21446, 'Repressed Polycomb': 9445, 'Heterochromatin': 6367, 'Enhancer': 3238, 'Bivalent TSS': 5})\n",
      "seedlings_H3K9ac.fa Counter({'Transcription': 33236, 'Enhancer': 8427, 'Heterochromatin': 7630, 'Repressed Polycomb': 6252, 'Bivalent TSS': 428})\n"
     ]
    }
   ],
   "source": [
    "for i in predict_dict:\n",
    "    print(i, predict_dict[i]['sta_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8c03261d-9c1c-4484-abb2-ea6be717ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_term = []\n",
    "for rec in predict_dict['random_n100k_w1k_noN.fa']['sta_res']:\n",
    "    max_term.append(sorted(rec.items(), key=lambda x:x[1])[-1][0])\n",
    "\n",
    "with open('../cross/taes/random_n100k_w1k_noN_predMaxLabel.txt','w') as f:\n",
    "    for rec in max_term:\n",
    "        f.write(rec+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_python",
   "language": "python",
   "name": "ml_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
